{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TvyemfDlDmu"
   },
   "source": [
    "### Coursework coding instructions (please also see full coursework spec)\n",
    "\n",
    "Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n",
    "\n",
    "For the task you choose you will need to do two approaches:\n",
    "  - Approach 1, which can use use pre-trained embeddings / models\n",
    "  - Approach 2, which should not use any pre-trained embeddings or models\n",
    "We should be able to run both approaches from the same colab file\n",
    "\n",
    "#### Running your code:\n",
    "  - Your models should run automatically when running your colab file without further intervention\n",
    "  - For each task you should automatically output the performance of both models\n",
    "  - Your code should automatically download any libraries required\n",
    "\n",
    "#### Structure of your code:\n",
    "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
    "  - Otherwise there are no restrictions on what you can do in your code\n",
    "\n",
    "#### Documentation:\n",
    "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
    "\n",
    "#### Reproducibility:\n",
    "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
    "\n",
    "Good luck! We are really looking forward to seeing your reports and your model code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShZnoBC3IwQM",
    "outputId": "e6261e66-45a7-4c85-bd84-1c08ec89927f"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_dir = '/content/drive/MyDrive/'\n",
    "except Exception:\n",
    "    data_dir = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRWFk-kelDoA",
    "outputId": "57729f5d-7cd7-4606-8f53-abbcc898f967"
   },
   "outputs": [],
   "source": [
    "# You will need to download any word embeddings required for your code, e.g.:\n",
    "\n",
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !unzip glove.6B.zip\n",
    "\n",
    "# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n",
    "\n",
    "#! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV6UcBDWEGUr",
    "outputId": "fb047824-f5c9-44e4-a7c5-5bfd138b218c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ekphrasis in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (0.5.1)\n",
      "Requirement already satisfied: gensim in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: spacy in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (3.0.3)\n",
      "Requirement already satisfied: nltk in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: ujson in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from ekphrasis) (4.0.2)\n",
      "Requirement already satisfied: tqdm in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from ekphrasis) (4.58.0)\n",
      "Requirement already satisfied: colorama in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from ekphrasis) (0.4.3)\n",
      "Requirement already satisfied: ftfy in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from ekphrasis) (5.9)\n",
      "Requirement already satisfied: termcolor in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from ekphrasis) (1.1.0)\n",
      "Requirement already satisfied: matplotlib in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from ekphrasis) (3.3.4)\n",
      "Requirement already satisfied: numpy in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from ekphrasis) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from gensim) (1.6.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: jinja2 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (2.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (44.0.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (8.0.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: pathy in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (1.7.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy) (20.3)\n",
      "Requirement already satisfied: regex in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: joblib in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: wcwidth in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from ftfy->ekphrasis) (0.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from matplotlib->ekphrasis) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from matplotlib->ekphrasis) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from matplotlib->ekphrasis) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from matplotlib->ekphrasis) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from matplotlib->ekphrasis) (8.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: en-core-web-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl#egg=en_core_web_sm==3.0.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (3.0.0)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from en-core-web-sm==3.0.0) (3.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: pathy in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.22.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: setuptools in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (44.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.3)\n",
      "Requirement already satisfied: jinja2 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.58.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from pathy->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=0.23 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-lg==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.0.0/en_core_web_lg-3.0.0-py3-none-any.whl (778.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 778.8 MB 10 kB/s  eta 0:00:0111     |███████████████████▍            | 470.5 MB 99.7 MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from en-core-web-lg==3.0.0) (3.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.22.0)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: pathy in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (4.58.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (8.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (20.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (44.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: jinja2 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.11.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.19.4)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from pathy->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.1.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (7.1.2)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.0.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!pip install ekphrasis gensim spacy nltk\n",
    "!python -m spacy download 'en_core_web_sm'\n",
    "!python -m spacy download 'en_core_web_lg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export GENSIM_DATA_DIR='./data/'\n",
    "# python -m gensim.downloader --download glove-twitter-25\n",
    "# python -m gensim.downloader --download word2vec-google-news-300\n",
    "# python -m gensim.downloader --download fasttext-wiki-news-subwords-300\n",
    "# python -m gensim.downloader --download glove-twitter-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "WX9TqmK7lDoK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import spacy\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "# from ekphrasis.dicts.noslang.slangdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "X09jt8VRlDoM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting random seed and device\n",
    "SEED = 1\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(f'{data_dir}/train.csv')\n",
    "test_df = pd.read_csv(f'{data_dir}/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/homes/rrr2417/gensim-data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "T9wrBEX_sGrT",
    "outputId": "e117b2f2-bec7-4566-a270-c3c16deb016c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>edit</th>\n",
       "      <th>grades</th>\n",
       "      <th>meanGrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14530</td>\n",
       "      <td>France is ‘ hunting down its citizens who join...</td>\n",
       "      <td>twins</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13034</td>\n",
       "      <td>Pentagon claims 2,000 % increase in Russian tr...</td>\n",
       "      <td>bowling</td>\n",
       "      <td>33110</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8731</td>\n",
       "      <td>Iceland PM Calls Snap Vote as Pedophile Furor ...</td>\n",
       "      <td>party</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>In an apparent first , Iran and Israel &lt;engage...</td>\n",
       "      <td>slap</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6164</td>\n",
       "      <td>Trump was told weeks ago that Flynn misled &lt;Vi...</td>\n",
       "      <td>school</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           original     edit  grades  \\\n",
       "0  14530  France is ‘ hunting down its citizens who join...    twins   10000   \n",
       "1  13034  Pentagon claims 2,000 % increase in Russian tr...  bowling   33110   \n",
       "2   8731  Iceland PM Calls Snap Vote as Pedophile Furor ...    party   22100   \n",
       "3     76  In an apparent first , Iran and Israel <engage...     slap   20000   \n",
       "4   6164  Trump was told weeks ago that Flynn misled <Vi...   school       0   \n",
       "\n",
       "   meanGrade  \n",
       "0        0.2  \n",
       "1        1.6  \n",
       "2        1.0  \n",
       "3        0.4  \n",
       "4        0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "bU7039mZsVC7",
    "outputId": "47fee855-afc4-491c-d3fc-cea8afef4c98"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grades</th>\n",
       "      <th>meanGrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9652.000000</td>\n",
       "      <td>9.652000e+03</td>\n",
       "      <td>9652.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7539.845213</td>\n",
       "      <td>2.048111e+11</td>\n",
       "      <td>0.935571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4359.342192</td>\n",
       "      <td>8.211835e+12</td>\n",
       "      <td>0.583643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3756.750000</td>\n",
       "      <td>1.110000e+04</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7510.500000</td>\n",
       "      <td>2.111000e+04</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11325.250000</td>\n",
       "      <td>3.210000e+04</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15095.000000</td>\n",
       "      <td>3.333332e+14</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id        grades    meanGrade\n",
       "count   9652.000000  9.652000e+03  9652.000000\n",
       "mean    7539.845213  2.048111e+11     0.935571\n",
       "std     4359.342192  8.211835e+12     0.583643\n",
       "min        1.000000  0.000000e+00     0.000000\n",
       "25%     3756.750000  1.110000e+04     0.400000\n",
       "50%     7510.500000  2.111000e+04     0.800000\n",
       "75%    11325.250000  3.210000e+04     1.400000\n",
       "max    15095.000000  3.333332e+14     3.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSK-xxIWsgoA"
   },
   "source": [
    "### Analysing Data Distribution and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4q1QNdzmMXxQ",
    "outputId": "e48c5641-9c17-4692-c979-73cdc78d05c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           1468\n",
       "original     1468\n",
       "edit         1468\n",
       "grades       1468\n",
       "meanGrade    1468\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_std = train_df.meanGrade.std()\n",
    "grade_mean = train_df.meanGrade.mean()\n",
    "ub = grade_mean + grade_std * 3\n",
    "lb = grade_mean - grade_std\n",
    "\n",
    "train_df[(train_df['meanGrade'] > ub) | (train_df['meanGrade'] < lb)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5836430877881276, 0.9355712114933001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_std, grade_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlC3UY-hNOEF",
    "outputId": "f627aefa-6979-4439-a75b-add38133a4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 317 entries, 70 to 9590\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         317 non-null    int64  \n",
      " 1   original   317 non-null    object \n",
      " 2   edit       317 non-null    object \n",
      " 3   grades     317 non-null    int64  \n",
      " 4   meanGrade  317 non-null    float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 14.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df[train_df['meanGrade'] >= 2.2].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6GaMGUhUqoI",
    "outputId": "10057e5b-2a5b-4e09-8f65-01cfee9d0ddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9652 entries, 0 to 9651\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         9652 non-null   int64  \n",
      " 1   original   9652 non-null   object \n",
      " 2   edit       9652 non-null   object \n",
      " 3   grades     9652 non-null   int64  \n",
      " 4   meanGrade  9652 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 377.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2       , 1.6       , 1.        , 0.4       , 0.        ,\n",
       "       1.2       , 0.8       , 1.4       , 0.6       , 1.8       ,\n",
       "       2.2       , 2.        , 2.4       , 1.3       , 2.06666667,\n",
       "       0.9       , 2.6       , 0.5       , 2.8       , 1.5       ,\n",
       "       1.9       , 1.7       , 3.        , 1.1       , 0.7       ,\n",
       "       2.13333333, 2.5       , 2.1       , 0.86666667, 2.3       ,\n",
       "       0.3       , 1.33333333, 1.53333333])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.meanGrade.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000     523\n",
       "0.200000     928\n",
       "0.300000       2\n",
       "0.400000    1100\n",
       "0.500000       4\n",
       "0.600000    1166\n",
       "0.700000       4\n",
       "0.800000    1186\n",
       "0.866667       1\n",
       "0.900000       7\n",
       "1.000000    1155\n",
       "1.100000      11\n",
       "1.200000    1017\n",
       "1.300000      13\n",
       "1.333333       1\n",
       "1.400000     819\n",
       "1.500000       7\n",
       "1.533333       1\n",
       "1.600000     635\n",
       "1.700000       7\n",
       "1.800000     430\n",
       "1.900000       5\n",
       "2.000000     308\n",
       "2.066667       1\n",
       "2.100000       3\n",
       "2.133333       1\n",
       "2.200000     167\n",
       "2.300000       2\n",
       "2.400000      94\n",
       "2.500000       1\n",
       "2.600000      38\n",
       "2.800000      13\n",
       "3.000000       2\n",
       "Name: meanGrade, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.meanGrade.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.meanGrade.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, ub):\n",
    "    _df = df.copy()\n",
    "    return _df[(_df.meanGrade <= ub)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "remove_outliers(train_df, ub=2.2).meanGrade.hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaEL0KmMtH-0"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "Ukhx1gLlthg2"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENSIM LIST OF WORD EMBEDDINGS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('GENSIM LIST OF WORD EMBEDDINGS')\n",
    "api.info()['models'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('./data/fasttext-wiki-news-subwords-300/fasttext-wiki-news-subwords-300.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ekphrasis Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VekS8ZMqaiUj",
    "outputId": "874b0006-10c9-4f55-84ea-6562f9285484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n",
      "Reading english - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "text_processor = TextPreProcessor(\n",
    "    annotate=['hashtag'],\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"english\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"english\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct=True,  # spell correction for elongated words\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_ascii_apostrophe = 0\n",
    "apostrophe_s = 12\n",
    "apostrophe_s_2 = 43\n",
    "contraction_won_t = 48\n",
    "contraction_won_t_2 = 264\n",
    "punct_check = 50\n",
    "contraction_isnt_2 = 66\n",
    "hashtag = 425 \n",
    "hashtag2 = 529 \n",
    "punct_exclaim = 80\n",
    "punct_question = 27\n",
    "punct_dash = 26\n",
    "contraction_dont = 128\n",
    "contraction_hell = 131\n",
    "punct_twitter_handle = 4388\n",
    "\n",
    "test_sentences = [\n",
    "    fancy_ascii_apostrophe,\n",
    "    apostrophe_s,\n",
    "    apostrophe_s_2,\n",
    "    contraction_won_t,\n",
    "    contraction_won_t_2,\n",
    "    punct_check,\n",
    "    contraction_isnt_2,\n",
    "    hashtag,\n",
    "    hashtag2, \n",
    "    punct_exclaim,\n",
    "    punct_question,\n",
    "    punct_dash,\n",
    "    contraction_dont,\n",
    "    contraction_hell,\n",
    "    punct_twitter_handle,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Hfd-qlwhJsYw",
    "outputId": "c673c3c5-33dd-4732-b5a1-92f58fcb297f",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>edit</th>\n",
       "      <th>grades</th>\n",
       "      <th>meanGrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14530</td>\n",
       "      <td>France is ‘ hunting down its citizens who join...</td>\n",
       "      <td>twins</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7614</td>\n",
       "      <td>Trump 's 2nd Nominee for &lt;Army/&gt; Secretary Wit...</td>\n",
       "      <td>Class</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5732</td>\n",
       "      <td>Fox 's James Murdoch rebukes &lt;Trump/&gt; over Cha...</td>\n",
       "      <td>grits</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3274</td>\n",
       "      <td>Kelly wo n't commit to defending DACA in &lt;cour...</td>\n",
       "      <td>space</td>\n",
       "      <td>33100</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>13786</td>\n",
       "      <td>Franken Reiterates He Wo n't &lt;Resign/&gt; : ' I K...</td>\n",
       "      <td>diet</td>\n",
       "      <td>31111</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>13443</td>\n",
       "      <td>Rand Paul : Saudi Arabia ’s Role in Backing &lt;T...</td>\n",
       "      <td>Turpentine</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>7780</td>\n",
       "      <td>This Is n't ' Another Watergate ' But It Plays...</td>\n",
       "      <td>Vaudeville</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>13225</td>\n",
       "      <td>Steve Bannon &lt;Meets/&gt; with Billionaire Mercer ...</td>\n",
       "      <td>canoodles</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>3636</td>\n",
       "      <td>China Is Attempting To &lt;Muzzle/&gt; #MeToo</td>\n",
       "      <td>start</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>8947</td>\n",
       "      <td>Trump to Dems : Of course I colluded , big &lt;de...</td>\n",
       "      <td>time</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11124</td>\n",
       "      <td>If America is Great Again , Why Is the &lt;Dollar...</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>22210</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12583</td>\n",
       "      <td>Oregon : 20-Year-Old Sues Kroger for &lt;Refusing...</td>\n",
       "      <td>trying</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2104</td>\n",
       "      <td>Cold weather : Do n't &lt;leave/&gt; these things in...</td>\n",
       "      <td>Cook</td>\n",
       "      <td>21100</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>6095</td>\n",
       "      <td>' I think he 'll be just fine ' : Trump hints ...</td>\n",
       "      <td>incarceration</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>12579</td>\n",
       "      <td>Who Is The Mystery &lt;Man/&gt; Behind @realDonaldTr...</td>\n",
       "      <td>turnip</td>\n",
       "      <td>32100</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           original           edit  \\\n",
       "0     14530  France is ‘ hunting down its citizens who join...          twins   \n",
       "12     7614  Trump 's 2nd Nominee for <Army/> Secretary Wit...          Class   \n",
       "43     5732  Fox 's James Murdoch rebukes <Trump/> over Cha...          grits   \n",
       "48     3274  Kelly wo n't commit to defending DACA in <cour...          space   \n",
       "264   13786  Franken Reiterates He Wo n't <Resign/> : ' I K...           diet   \n",
       "50    13443  Rand Paul : Saudi Arabia ’s Role in Backing <T...     Turpentine   \n",
       "66     7780  This Is n't ' Another Watergate ' But It Plays...     Vaudeville   \n",
       "425   13225  Steve Bannon <Meets/> with Billionaire Mercer ...      canoodles   \n",
       "529    3636            China Is Attempting To <Muzzle/> #MeToo          start   \n",
       "80     8947  Trump to Dems : Of course I colluded , big <de...           time   \n",
       "27    11124  If America is Great Again , Why Is the <Dollar...   intelligence   \n",
       "26    12583  Oregon : 20-Year-Old Sues Kroger for <Refusing...         trying   \n",
       "128    2104  Cold weather : Do n't <leave/> these things in...           Cook   \n",
       "131    6095  ' I think he 'll be just fine ' : Trump hints ...  incarceration   \n",
       "4388  12579  Who Is The Mystery <Man/> Behind @realDonaldTr...         turnip   \n",
       "\n",
       "      grades  meanGrade  \n",
       "0      10000        0.2  \n",
       "12     22100        1.0  \n",
       "43     10000        0.2  \n",
       "48     33100        1.4  \n",
       "264    31111        1.4  \n",
       "50     10000        0.2  \n",
       "66     11000        0.4  \n",
       "425    21000        0.6  \n",
       "529        0        0.0  \n",
       "80     21000        0.6  \n",
       "27     22210        1.4  \n",
       "26     22100        1.0  \n",
       "128    21100        0.8  \n",
       "131    21000        0.6  \n",
       "4388   32100        1.2  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[test_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging replacements in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    France is ‘ hunting down its citizens who join...\n",
       "1    Pentagon claims 2,000 % increase in Russian tr...\n",
       "2    Iceland PM Calls Snap Vote as Pedophile Furor ...\n",
       "3    In an apparent first , Iran and Israel slap ea...\n",
       "4    Trump was told weeks ago that Flynn misled sch...\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_sentences = train_df[['original', 'edit']] \\\n",
    "    .apply(lambda x: re.subn(\"<.*/>\", x[1], x[0])[0], axis=1)\n",
    "edited_sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWF1u2qXor6-",
    "outputId": "2015abfc-6c57-4156-d4d9-b8edc26acb70"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-649f357cc77e>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  edited_sentences.str.replace(\" (?P<one>\\w*'\\w+)\", lambda x: x.group(\"one\"))[[0, 12, 43, 48, 50, 264, 66]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      France is ‘ hunting down its citizens who join...\n",
       "12     Trump's 2nd Nominee for Class Secretary Withdraws\n",
       "43     Fox's James Murdoch rebukes grits over Charlot...\n",
       "48        Kelly won't commit to defending DACA in space \n",
       "50     Rand Paul : Saudi Arabia ’s Role in Backing Tu...\n",
       "264    Franken Reiterates He Won't diet : ' I Know Th...\n",
       "66     This Isn't ' Another Watergate ' But It Plays ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_sentences.str.replace(\" (?P<one>\\w*'\\w+)\", lambda x: x.group(\"one\"))[[0, 12, 43, 48, 50, 264, 66]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition (NER)\n",
    "\n",
    "Pretrained Word2Vec doesn't represent \"france\" and \"France\" in the same way (case sensitive). There are many named entities for which this happens which could be problematic if we want to utilities context sensitive representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy \n",
    "\n",
    "def ner_viewer(sentence):\n",
    "    trial_doc = nlp(sentence)\n",
    "\n",
    "    for ent in trial_doc.ents:\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "    displacy.render(trial_doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France 0 6 GPE\n",
      "Iraq 74 78 GPE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    France\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is ' hunting down its citizens who joined twins ' without trial in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Iraq\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump 0 12 PERSON\n",
      "Twitter 51 58 PRODUCT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Donald Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " revives ' Crooked penis ' nickname on \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Twitter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " only to be trumped by election rival with ' covfefe ' KO</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nobel Prize 30 41 WORK_OF_ART\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Donkey calls for trump to win \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nobel Prize\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_viewer(sents.edited_sentences[0])\n",
    "ner_viewer(sents.edited_sentences[1120])\n",
    "ner_viewer(sents.edited_sentences[1477])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing similiarty of vectors under google news embeddings\n",
    "# top 10 similiarities\n",
    "\n",
    "def similiarities(model, word1, word2, top_n=1000):\n",
    "    top_words_list = model.similar_by_word(word1, topn=top_n)\n",
    "    top_words_list2 = model.similar_by_word(word2, topn=top_n)\n",
    "    top_words_set = set(w for w, sim in top_words_list)\n",
    "    top_words_set2 = set(w for w, sim in top_words_list2)\n",
    "    return top_words_list, top_words_list2, top_words_set.intersection(top_words_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-France',\n",
       " 'AirFrance',\n",
       " 'Belgium',\n",
       " 'Belguim',\n",
       " 'Boulogne',\n",
       " 'Boulogne-Billancourt',\n",
       " 'Bretagne',\n",
       " 'Britain',\n",
       " 'Britan',\n",
       " 'Britanny',\n",
       " 'Brittany',\n",
       " 'Chateauroux',\n",
       " 'Europe',\n",
       " 'France-',\n",
       " 'France.',\n",
       " 'Franch',\n",
       " 'Frence',\n",
       " 'French',\n",
       " 'Ile-de-France',\n",
       " 'Italy',\n",
       " 'Marseille',\n",
       " 'Nimes',\n",
       " 'Paris',\n",
       " 'Poitou-Charentes',\n",
       " 'Provence',\n",
       " 'Spain',\n",
       " 'Tarbes',\n",
       " 'Versaille'}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simlist1, simlist2, intersection = similiarities(embeddings, 'France', 'france')\n",
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Trumps', 0.7959632873535156), ('Trumpian', 0.7332221269607544), ('Trumping', 0.7272778749465942), ('Trumpism', 0.7086310982704163), ('Drumpf', 0.7022296190261841), ('Trump-like', 0.6928916573524475), ('Anti-Trump', 0.6859002709388733), ('Trump-branded', 0.6830976009368896), ('Trumped', 0.6769288778305054), ('Trump-related', 0.6740255355834961)]\n",
      "\n",
      "[('trumps', 0.8457010388374329), ('trumping', 0.7876768112182617), ('non-trump', 0.7490019798278809), ('trumped', 0.7124733328819275), ('notrump', 0.6544545888900757), ('supercede', 0.6326020956039429), ('overrule', 0.6288058757781982), ('no-trump', 0.6278952360153198), ('override', 0.6258442401885986), ('supersede', 0.6115215420722961)]\n"
     ]
    }
   ],
   "source": [
    "simlist1, simlist2, intersection = similiarities(embeddings, 'Trump', 'trump')\n",
    "print(simlist1[:10])\n",
    "print()\n",
    "print(simlist2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trump has a different meaning to trump, where the first ones refers to the ex-President and the second is the verb. For this reason, in the context of headlines, we are safer capitalising all words that are named entities, when we are using news-specific pretrained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "AjwJSZyLOkWM"
   },
   "outputs": [],
   "source": [
    "# def tokenize(\n",
    "#     data, \n",
    "#     is_lower=True, \n",
    "#     remove_stopwords=True, \n",
    "#     remove_puncts=True, \n",
    "#     remove_num=True, \n",
    "#     remove_currency=True\n",
    "# ):\n",
    "#     # Params for \n",
    "#     clean_text_param = {\n",
    "#         \"lower\":False,                     # lowercase text\n",
    "#         \"no_line_breaks\":True,           # fully strip line breaks as opposed to only normalizing them\n",
    "#         \"no_urls\":False,                  # replace all URLs with a special token\n",
    "#         \"no_emails\":False,                # replace all email addresses with a special token\n",
    "#         \"no_phone_numbers\":False,         # replace all phone numbers with a special token\n",
    "#         \"no_numbers\":False,               # replace all numbers with a special token\n",
    "#         \"no_digits\":False,                # replace all digits with a special token\n",
    "#         \"no_currency_symbols\":True,      # replace all currency symbols with a special token\n",
    "#         \"no_punct\":True,                 # remove punctuations\n",
    "#         \"replace_with_punct\":\"\",          # instead of removing punctuations you may replace them\n",
    "#         \"replace_with_number\":\"\",\n",
    "#         \"replace_with_digit\":\"\",\n",
    "#         \"replace_with_currency_symbol\":\"\",\n",
    "#         \"lang\":\"en\"                       # set to 'de' for German special handling\n",
    "#     }\n",
    "\n",
    "#     text_processor = TextPreProcessor(\n",
    "#         annotate=['hashtag'],\n",
    "#         fix_html=True,  # fix HTML tokens\n",
    "        \n",
    "#         # corpus from which the word statistics are going to be used \n",
    "#         # for word segmentation \n",
    "#         segmenter=\"english\", \n",
    "        \n",
    "#         # corpus from which the word statistics are going to be used \n",
    "#         # for spell correction\n",
    "#         corrector=\"english\", \n",
    "        \n",
    "#         unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "#         unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "#         spell_correct=True,\n",
    "#     )\n",
    "\n",
    "#     tokenized_corpus = []\n",
    "\n",
    "#     for sentence in data:\n",
    "\n",
    "#         tokenized_sentence = []\n",
    "#         # processed_sentence = text_processor.pre_process_doc(sentence)\n",
    "#         # clean_sentence = clean(processed_sentence, **clean_text_param)\n",
    "#         spacy_doc = nlp(sentence)\n",
    "\n",
    "#         for token in spacy_doc:\n",
    "#             processed_token = token\n",
    "#             if (remove_stopwords and processed_token.is_stop):\n",
    "#                 continue\n",
    "#             elif (remove_puncts and processed_token.is_punct):\n",
    "#               continue\n",
    "#             elif (remove_num and processed_token.is_digit):\n",
    "#               continue\n",
    "#             elif (remove_currency and processed_token.is_currency):\n",
    "#               continue\n",
    "#             elif (is_lower):\n",
    "#               tokenized_sentence.append(token.lower_)\n",
    "#             else:\n",
    "#               tokenized_sentence.append(token.text)\n",
    "\n",
    "#         tokenized_corpus.append(tokenized_sentence)\n",
    "\n",
    "#     return tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "EB4iwrfO6Hte"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalisation_by_ner(sentence, entities=['GPE', 'ORG', 'NORP', 'PERSON']):\n",
    "#     _df = df.copy()\n",
    "\n",
    "#     for i in df.edited_sentences.index:\n",
    "    edited_row = []\n",
    "\n",
    "#         trial_doc = nlp(_df.loc[i, 'edited_sentences'])\n",
    "        \n",
    "#         for tok in trial_doc:\n",
    "#             if tok.ent_type_ in entities:\n",
    "#                 edited_row.append(tok.text)\n",
    "#             else:\n",
    "#                 edited_row.append(tok.text.lower())\n",
    "                \n",
    "#         _df.loc[i, 'edited_sentences'] = ' '.join(edited_row)\n",
    "    \n",
    "#     return _df\n",
    "    trial_doc = nlp(sentence)\n",
    "        \n",
    "    for tok in trial_doc:\n",
    "        if tok.ent_type_ in entities:\n",
    "            edited_row.append(tok.text)\n",
    "        else:\n",
    "            edited_row.append(tok.text.lower())\n",
    "    return ' '.join(edited_row)\n",
    "\n",
    "\n",
    "def remove_stopwords_and_punct(df):\n",
    "    nltk.download('stopwords')\n",
    "    stops = stopwords.words('english')\n",
    "    \n",
    "    punct = \"[\\.,:;\\(\\)\\[\\]@\\-\\$£]\"\n",
    "    \n",
    "    _df = df.copy()\n",
    "    \n",
    "    _df.edited_sentences = _df.edited_sentences \\\n",
    "        .apply(lambda x: \" \".join([w for w in x.split(\" \") if w not in stops])) \\\n",
    "        # .str.replace(punct, \"\", regex=True)\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i ca n't do this\""
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalisation_by_ner(\"I can't do this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "ZBvBsifItXR1"
   },
   "outputs": [],
   "source": [
    "# Word replacement\n",
    "# Join the contractions\n",
    "# Tokenize\n",
    "# remove stop words\n",
    "# remove punct EXCEPT ! ? #\n",
    "# Twitter handles\n",
    "\n",
    "def preprocess_keep_stopwords(df):\n",
    "    _df = pd.DataFrame(index=df.index, columns=['edited_sentences', 'meanGrade'])\n",
    "\n",
    "    _df['meanGrade'] = df.meanGrade\n",
    "\n",
    "    text_processor = TextPreProcessor(\n",
    "        fix_html=True,  # fix HTML tokens\n",
    "\n",
    "        # corpus from which the word statistics are going to be used \n",
    "        # for word segmentation \n",
    "        segmenter=\"english\", \n",
    "\n",
    "        # corpus from which the word statistics are going to be used \n",
    "        # for spell correction\n",
    "        corrector=\"english\", \n",
    "\n",
    "        unpack_hashtags=False,  # perform word segmentation on hashtags\n",
    "        unpack_contractions=False,  # Unpack contractions (can't -> can not)\n",
    "        spell_correct=True,  # spell correction for elongated words\n",
    "    )\n",
    "    punct = \"[\\.,:;\\(\\)\\[\\]@\\-\\$£]\"\n",
    "\n",
    "    # Word replacement + join the contractions\n",
    "    # NOTE: need to deal with ' '\n",
    "    # NOTE: Numbers/digits have not been removed\n",
    "    # NOTE: We have removed all stop words. We analysed the sentiment of the stop \n",
    "    # words in the training set to determine if removing them would negatively \n",
    "    # affect our results. The motivation for this check was that any word with a \n",
    "    # sentiment would affect the funniness score of the sentence. \n",
    "    # Since stop words have no sentiment, they have been removed\n",
    "    # This doesn't retain any twitter handles, but retains the hashtags\n",
    "\n",
    "    _df['edited_sentences'] = df[['original', 'edit']] \\\n",
    "        .apply(lambda x: re.subn(\"<.*/>\", x[1], x[0])[0], axis=1) \\\n",
    "        .apply(lambda x: capitalisation_by_ner(x)) \\\n",
    "        .str.replace(\" (?P<one>\\w*'\\w+)\", lambda x: x.group(\"one\")) \\\n",
    "        .apply(lambda x: text_processor.pre_process_doc(x)) \\\n",
    "        .str.replace(\"#\", \"# \") \\\n",
    "        .str.replace(\"[‘’]\", \"'\") \\\n",
    "        .str.replace(\"'s\", \"\") \\\n",
    "        .str.replace(punct, \"\")\n",
    "\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUz6nRuKxGQt",
    "outputId": "d9a438b5-0614-4dda-fb36-78cc6b930d5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-221-8689799d98f6>:40: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  _df['edited_sentences'] = df[['original', 'edit']] \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edited_sentences</th>\n",
       "      <th>meanGrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France is ' hunting down its citizens who join...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Trump 2nd nominee for class secretary withdraws</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Fox James Murdoch rebukes grits over Charlotte...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Kelly won't commit to defending DACA in space</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Franken reiterates he won't diet  ' i know tha...</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Rand Paul  Saudi Arabia  role in backing turpe...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>this isn't ' another watergate ' but it plays ...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Steve Bannon canoodles with billionaire Mercer...</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>China is attempting to start #  metoo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>trump to Dems  of course i colluded  big time ...</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>if America is great again  why is the intellig...</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Oregon  20  year  old sues Kroger for trying t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>cold weather  don't Cook these things in your ...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>' i think he'll be just fine '  trump hints at...</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>who is the mystery turnip behind realdonaldtru...</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       edited_sentences  meanGrade\n",
       "0     France is ' hunting down its citizens who join...        0.2\n",
       "12      Trump 2nd nominee for class secretary withdraws        1.0\n",
       "43    Fox James Murdoch rebukes grits over Charlotte...        0.2\n",
       "48        Kelly won't commit to defending DACA in space        1.4\n",
       "264   Franken reiterates he won't diet  ' i know tha...        1.4\n",
       "50    Rand Paul  Saudi Arabia  role in backing turpe...        0.2\n",
       "66    this isn't ' another watergate ' but it plays ...        0.4\n",
       "425   Steve Bannon canoodles with billionaire Mercer...        0.6\n",
       "529               China is attempting to start #  metoo        0.0\n",
       "80    trump to Dems  of course i colluded  big time ...        0.6\n",
       "27    if America is great again  why is the intellig...        1.4\n",
       "26    Oregon  20  year  old sues Kroger for trying t...        1.0\n",
       "128   cold weather  don't Cook these things in your ...        0.8\n",
       "131   ' i think he'll be just fine '  trump hints at...        0.6\n",
       "4388  who is the mystery turnip behind realdonaldtru...        1.2"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = preprocess_keep_stopwords(train_df)\n",
    "sents.loc[test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edited_sentences</th>\n",
       "      <th>meanGrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France is ' hunting down its citizens who join...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pentagon claims 2000 % increase in Russian tro...</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iceland pm calls snap vote as pedophile furor ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in an apparent first   Iran and Israel slap ea...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump was told weeks ago that Flynn misled sch...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all 22 sounds Trump made in his speech to Cong...</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>new DOJ alert system will flag laughter agains...</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>as someone who grew up among fundamentalist mo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Canadians may pay more taxes than Americans   ...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dutch minister resigns in drug baron blow</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dozens dead in possible gas bloating in Syria ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>how trump just made pilates less safe</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>trump 2nd nominee for class secretary withdraws</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the GOP just ca n't remember the ' 80s</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mississippi law endorses antiLGBT bias   attor...</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>' Chibok salamis ' reunited with families</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bill aiming to marry Christians   other minori...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pulled over in a rental car   with junk in the...</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>US president forced to leave New Zealand after...</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Erdogan rejects Arab demands   turkish turkeys...</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mark Cuban wants constitution changed to make ...</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Russian trolls would love the ' honest hotdogs...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>questions about Trump stupefy Republican Sen C...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>27 billion christmas cookies in Spain   video</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>US imposes metal tariffs on key holes</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>what we learned from enduring a weeklong news ...</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Oregon   20yearold sues Kroger for trying to s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>if America is great again   why is the intelli...</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>everyone quits Twitter after offending with st...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>trump avoids pointing to Saudis ' human pyrami...</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     edited_sentences  meanGrade\n",
       "0   France is ' hunting down its citizens who join...        0.2\n",
       "1   Pentagon claims 2000 % increase in Russian tro...        1.6\n",
       "2   Iceland pm calls snap vote as pedophile furor ...        1.0\n",
       "3   in an apparent first   Iran and Israel slap ea...        0.4\n",
       "4   Trump was told weeks ago that Flynn misled sch...        0.0\n",
       "5   all 22 sounds Trump made in his speech to Cong...        1.2\n",
       "6   new DOJ alert system will flag laughter agains...        1.2\n",
       "7   as someone who grew up among fundamentalist mo...        1.0\n",
       "8   Canadians may pay more taxes than Americans   ...        0.2\n",
       "9           Dutch minister resigns in drug baron blow        0.0\n",
       "10  dozens dead in possible gas bloating in Syria ...        1.0\n",
       "11              how trump just made pilates less safe        0.8\n",
       "12    trump 2nd nominee for class secretary withdraws        1.0\n",
       "13             the GOP just ca n't remember the ' 80s        1.4\n",
       "14  Mississippi law endorses antiLGBT bias   attor...        0.6\n",
       "15          ' Chibok salamis ' reunited with families        0.2\n",
       "16  Bill aiming to marry Christians   other minori...        0.8\n",
       "17  pulled over in a rental car   with junk in the...        1.6\n",
       "18  US president forced to leave New Zealand after...        1.4\n",
       "19  Erdogan rejects Arab demands   turkish turkeys...        1.2\n",
       "20  Mark Cuban wants constitution changed to make ...        1.6\n",
       "21  Russian trolls would love the ' honest hotdogs...        1.0\n",
       "22  questions about Trump stupefy Republican Sen C...        0.4\n",
       "23      27 billion christmas cookies in Spain   video        1.0\n",
       "24              US imposes metal tariffs on key holes        0.2\n",
       "25  what we learned from enduring a weeklong news ...        1.4\n",
       "26  Oregon   20yearold sues Kroger for trying to s...        1.0\n",
       "27  if America is great again   why is the intelli...        1.4\n",
       "28  everyone quits Twitter after offending with st...        0.8\n",
       "29  trump avoids pointing to Saudis ' human pyrami...        1.4"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_sents = capitalisation_by_ner(sents)\n",
    "\n",
    "lower_sents.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "EVnif2UrILfr"
   },
   "outputs": [],
   "source": [
    "tokenized_words = sents.edited_sentences.map(lambda x: x.split(\" \"))\n",
    "oov_words = []\n",
    "\n",
    "for sentence in tokenized_words:\n",
    "    for word in sentence:\n",
    "        if word not in embeddings.vocab:\n",
    "            oov_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7fe4900bbb80>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVTWcELsIUd9",
    "outputId": "656a62f4-1dc3-467b-cce9-ea7cf43f81a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'': 7314, \"n't\": 117, \"won't\": 64, \"don't\": 50, \"isn't\": 35, \"can't\": 35, \"doesn't\": 24, \"he'll\": 15, 'Trumpcare': 15, 'rosenstein': 11, 'metoo': 9, 'manafort': 9, \"we'll\": 9, 'grenfell': 8, 'comey': 7, 'charlottesville': 7, 'AT&ampT': 7, \"DineshD'Souza\": 6, \"you're\": 6, 'Kushners': 6, \"shouldn't\": 6, \"aren't\": 6, 'glencore': 6, 'kaspersky': 6, \"weren't\": 6, \"didn't\": 6, \"couldn't\": 6, 'nkorea': 6, \"they're\": 6, 'cnnpoliticscom': 6, 'apnewsbreak': 5, 'irma': 5, 'tillerson': 5, \"BillO'Reilly\": 4, 'Manassian': 3, 'Nattering': 3, 'Nabobs': 3, 'deplorableness': 3, 'scalise': 3, 'Recuses': 3, \"MartinO'Malley\": 3, 'pocohontas': 3, '227000': 3, '138000': 3, 'q&ampa': 3, 'FLYNT': 3, 'Warmbier': 3, 'arbaeen': 3, 'jinping': 3, 'infowarscom': 3, 'Myeshia': 3, 'aesop': 3, 'sh*t': 3, 'gorsuch': 3, 'WomensMarch': 3, 'bigly': 3, 'disinvites': 3, 'covfefe': 3, \"hasn't\": 3, 'Schlapps': 3, 'Frexit': 3, 'raqqa': 3, 'whcd': 3, 'Nobost': 3, 'DURBIN': 3, \"O'Keefe\": 3, \"wasn't\": 3, 'Frightbart': 3, 'counterspies': 3, \"he'd\": 3, 'ar15': 3, \"i'd\": 3, 'Strzok': 3, 'usled': 3, 'maddow': 3, '`': 3, \"BetoO'Rourke\": 3, 'hbcus': 3, 'adulting': 3, 'Gunmam': 3, 'weaponizes': 3, 'icbms': 3, 'troway': 3, 'JPMORGAN': 3, \"wouldn't\": 3, 'ivanka': 3, '24473': 3, 'voterbase': 3, 'tweetstorm': 3, 'OnPolitics': 3, 'ca25': 3, 'fagggots': 3, 'Nigggers': 3, 'Regeni': 3, 'hjiab': 3, 'NoMoreNazi': 3, 'TrumpCare': 3, 'bannon': 3, 'Kuaishou': 3, 'tencent': 3, 'philando': 3, '361000': 3, 'destroye': 3, 'saloncom': 3, 'Choirul': 3, 'Trumpenomics': 3, 'westworld': 3, 'Crownprince': 3, 'mulvaney': 3, 'Pussyhats': 3, \"we're\": 3, 'realdonaldtrump': 3, 'creditloan': 3, 'sychologists': 3, 'GLICK': 3, 'cyberwars': 3, 'hb2': 3, 'MyPillow': 3, 'countermemo': 3, 'trumpism': 3, 'x27': 3, 'tweetstorms': 3, 'icrc': 3, 'NeverTrump': 3, 'uninsuredRepublican': 3, 'afrin': 3, 'analytica': 3, 'brexiteers': 3, 'bataclan': 3, \"hadn't\": 3, 'binomo': 3, '168000': 3, 'Skripal': 3, 'gabbanelli': 3, 'Cantabella': 3, 'Dotards': 2, 'Halfhearted': 2, '300mw': 2, 'Playbooks': 2, \"They're\": 2, 'Guantรกnamo': 2, 'hollyweed': 2, 'duterte': 2, 'pershing': 2, 'scaramucci': 2, 'nazca': 2, 'f*ck': 2, 'Dotard': 2, 'helwan': 2, 'trebek': 2, 'Trumpist': 2, \"o'reilly\": 2, 'Puigdemont': 2, \"o'rourke\": 2, 'impanels': 2, 'Kompromat': 2, 'brookfield': 1, 'orangeness': 1, 'canoodles': 1, 'Nightgowns': 1, 'transtemporalize': 1, 'cathey': 1, 'Deflates': 1, 'halloweeners': 1, 'Fends': 1, 'supersoaker': 1, 'myopics': 1, 'defenestrates': 1, 'Misplaces': 1, 'catawampus': 1, 'trumpist': 1, 'misanthropics': 1, 'vellicate': 1, 'Bustier': 1, 'Unfollowed': 1, 'Malingerer': 1, 'fakiness': 1, 'anbang': 1, 'piroshki': 1, 'eructations': 1, 'at&ampt': 1, 'Rollerskater': 1, 'cornholing': 1, 'scrubdown': 1, 'Hypnotise': 1, 'Hairpiece': 1, 'guantรกnamo': 1, 'primps': 1, 'lazies': 1, 'horoscopists': 1, 'thaad': 1, 'kennelmaster': 1, 'pussyfoots': 1, 'Cyberweapons': 1, 'oglings': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "oov_words_counter = Counter(oov_words)\n",
    "print(oov_words_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GR1O7LoUIr5G",
    "outputId": "a015c9fb-315d-425c-c0d1-7646953a0243"
   },
   "outputs": [],
   "source": [
    "word2vec.similarity(\"France\", \"france\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQwZNp4iI0vf"
   },
   "outputs": [],
   "source": [
    "word2vec.similar_by_word(\"France\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pV6XA-kd48jX",
    "outputId": "f1337447-07e4-4ada-9a93-9029e20eb73b"
   },
   "outputs": [],
   "source": [
    "print(\"don't\" in stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eI2-K57j8qkD"
   },
   "outputs": [],
   "source": [
    "corpus_words = set(\" \".join(list(sents.edited_sentences)).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uskm4E849AwZ"
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQrkD5W-8NyW"
   },
   "outputs": [],
   "source": [
    "exceptions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grLvEiHp-5Oa",
    "outputId": "14440bf0-d918-4c2b-f985-bddf0d6acfff"
   },
   "outputs": [],
   "source": [
    "nltk.download('opinion_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmnm3I4f_Bp0"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "pos_list=set(opinion_lexicon.positive())\n",
    "neg_list=set(opinion_lexicon.negative())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtaRXCoi_TAt",
    "outputId": "74df1b4b-0d38-40c3-d8f4-bb3e5c92d541"
   },
   "outputs": [],
   "source": [
    "print(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tmIlMuX9Fw_",
    "outputId": "a335c46a-8f5c-45ed-8d38-d794c0b85b6a"
   },
   "outputs": [],
   "source": [
    "inters = corpus_words.intersection(stops)\n",
    "(inters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foRjAsLX_fg0",
    "outputId": "fc1a826b-2453-488b-bc87-66647c9354e8"
   },
   "outputs": [],
   "source": [
    "inters.intersection(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBeaQIv-_lGn",
    "outputId": "42a74c95-92f2-4daa-9426-b97a30e81d38"
   },
   "outputs": [],
   "source": [
    "inters.intersection(neg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kl0ULjrq8ycq",
    "outputId": "f645cdfa-102b-4a4f-cda9-c957c1e6dbe4"
   },
   "outputs": [],
   "source": [
    "stop_words_tokenized = nlp(\" \".join(list(inters)))\n",
    "\n",
    "for token in stop_words_tokenized:\n",
    "    print(\"{}   {}\".format(token.text, token.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVVhUdIRyXjU",
    "outputId": "60f8ef87-baad-4c8d-dcb0-771ce2093baf"
   },
   "outputs": [],
   "source": [
    "indices = [0, 12, 43, 48, 50, 264, 66, 425, 529, 80, 27, 26, 128, 131, 4388]\n",
    "for i in indices:\n",
    "    print(sents.edited_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1ZppkAH2o2r",
    "outputId": "bc27e226-b350-48c6-b91f-c036a7630f59"
   },
   "outputs": [],
   "source": [
    "punct = \"[\\.,:;\\(\\)\\[\\]@\\$£]\"\n",
    "\n",
    "re.sub(punct, \"I am @mad\", \"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "3RCmF7xulDoP"
   },
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Proportion of training data for train compared to dev\n",
    "train_proportion = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "qAgZW6K1lDoR"
   },
   "outputs": [],
   "source": [
    "# We define our training loop\n",
    "def train(train_iter, dev_iter, model, number_epoch):\n",
    "    \"\"\"\n",
    "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    print(\"Training model.\")\n",
    "\n",
    "    for epoch in range(1, number_epoch+1):\n",
    "\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_sse = 0\n",
    "        no_observations = 0  # Observations used for training so far\n",
    "\n",
    "        for batch in train_iter:\n",
    "\n",
    "            feature, target = batch\n",
    "\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            # for RNN:\n",
    "            model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            model.hidden = model.init_hidden()\n",
    "\n",
    "            # print(feature)\n",
    "\n",
    "            predictions = model(feature).squeeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_fn(predictions, target)\n",
    "\n",
    "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "\n",
    "        valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
    "\n",
    "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
    "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
    "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "NzXeDgHmlDob"
   },
   "outputs": [],
   "source": [
    "# We evaluate performance on our dev set\n",
    "def eval(data_iter, model):\n",
    "    \"\"\"\n",
    "    Evaluating model performance on the dev set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_sse = 0\n",
    "    pred_all = []\n",
    "    trg_all = []\n",
    "    no_observations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_iter:\n",
    "            feature, target = batch\n",
    "\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            # for RNN:\n",
    "            model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            model.hidden = model.init_hidden()\n",
    "\n",
    "            predictions = model(feature).squeeze(1)\n",
    "            loss = loss_fn(predictions, target)\n",
    "\n",
    "            # We get the mse\n",
    "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
    "            sse, __ = model_performance(pred, trg)\n",
    "\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "            pred_all.extend(pred)\n",
    "            trg_all.extend(trg)\n",
    "\n",
    "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "2_22fHHElDog"
   },
   "outputs": [],
   "source": [
    "# How we print the model performance\n",
    "def model_performance(output, target, print_output=False):\n",
    "    \"\"\"\n",
    "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
    "    \"\"\"\n",
    "\n",
    "    sq_error = (output - target)**2\n",
    "\n",
    "    sse = np.sum(sq_error)\n",
    "    mse = np.mean(sq_error)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    if print_output:\n",
    "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
    "\n",
    "    return sse, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "susJPfGJllVF",
    "outputId": "2e6aa0bb-eb39-4cee-ff3a-4258a7d55a9d"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'edited_sentence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'edited_sentence'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-d6899e94f1e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edited_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m264\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'edited_sentence'"
     ]
    }
   ],
   "source": [
    "train_df['edited_sentence'][264]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9ttuDkfii2x",
    "outputId": "067cc711-bab8-4e23-d173-acad777df35f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-233-b1a317fe0130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenized_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edited_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m425\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edited_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_sents = tokenize([train_df['edited_sentence'][425], train_df['edited_sentence'][48]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlvcIregk222",
    "outputId": "28bad804-68a2-46d9-ab9d-301d4434cddb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edited_sentences</th>\n",
       "      <th>meanGrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France is ' hunting down its citizens who join...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pentagon claims 2000 % increase in Russian tro...</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iceland pm calls snap vote as pedophile furor ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in an apparent first  Iran and Israel slap eac...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump was told weeks ago that Flynn misled sch...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9647</th>\n",
       "      <td>state officials blast ' unprecedented ' DHS id...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9648</th>\n",
       "      <td>protesters rally for stewardesses detained at ...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9649</th>\n",
       "      <td>cruise line Carnival Corp joins the fight agai...</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650</th>\n",
       "      <td>Columbia police hunt woman seen with cake near...</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651</th>\n",
       "      <td>here what in The House  Approved Health food Bill</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9652 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       edited_sentences  meanGrade\n",
       "0     France is ' hunting down its citizens who join...        0.2\n",
       "1     Pentagon claims 2000 % increase in Russian tro...        1.6\n",
       "2     Iceland pm calls snap vote as pedophile furor ...        1.0\n",
       "3     in an apparent first  Iran and Israel slap eac...        0.4\n",
       "4     Trump was told weeks ago that Flynn misled sch...        0.0\n",
       "...                                                 ...        ...\n",
       "9647  state officials blast ' unprecedented ' DHS id...        0.0\n",
       "9648  protesters rally for stewardesses detained at ...        0.4\n",
       "9649  cruise line Carnival Corp joins the fight agai...        0.6\n",
       "9650  Columbia police hunt woman seen with cake near...        1.4\n",
       "9651  here what in The House  Approved Health food Bill        0.4\n",
       "\n",
       "[9652 rows x 2 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcxmqrKhlDoj"
   },
   "outputs": [],
   "source": [
    "def create_vocab(data):\n",
    "    \"\"\"\n",
    "    Creating a corpus of all the tokens used\n",
    "    \"\"\"\n",
    "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
    "\n",
    "    for sentence in data:\n",
    "\n",
    "        tokenized_sentence = []\n",
    "\n",
    "        for token in sentence.split(' '): # simplest split is\n",
    "\n",
    "            tokenized_sentence.append(token)\n",
    "\n",
    "        tokenized_corpus.append(tokenized_sentence)\n",
    "\n",
    "    # Create single list of all vocabulary\n",
    "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
    "\n",
    "    for sentence in tokenized_corpus:\n",
    "\n",
    "        for token in sentence:\n",
    "\n",
    "            if token not in vocabulary:\n",
    "\n",
    "                if True:\n",
    "                    vocabulary.append(token)\n",
    "\n",
    "    return vocabulary, tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzQ0KLXslDoq"
   },
   "outputs": [],
   "source": [
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    We add padding to our minibatches and create tensors for our model\n",
    "    '''\n",
    "\n",
    "    batch_labels = [l for f, l in batch]\n",
    "    batch_features = [f for f, l in batch]\n",
    "\n",
    "    batch_features_len = [len(f) for f, l in batch]\n",
    "\n",
    "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
    "\n",
    "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
    "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
    "\n",
    "    batch_labels = torch.FloatTensor(batch_labels)\n",
    "\n",
    "    return seq_tensor, batch_labels\n",
    "\n",
    "class Task1Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, train_data, labels):\n",
    "        self.x_train = train_data\n",
    "        self.y_train = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.x_train[item], self.y_train[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWaxTh2UlDoy"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2label = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
    "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n",
    "               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embedded = self.embedding(sentence)\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n",
    "\n",
    "        out = self.hidden2label(lstm_out[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iS4at8jJJNGG"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPdnr84aKgiB",
    "outputId": "943e1890-9015-4407-cd82-747bc7ef7cc0"
   },
   "outputs": [],
   "source": [
    "## Approach 1 code, using functions defined above:\n",
    "\n",
    "# We set our training data and test data\n",
    "training_data = sents['edited_sentence']\n",
    "test_data = sents['edited_sentence']\n",
    "\n",
    "# Creating word vectors\n",
    "training_vocab, training_tokenized_corpus = create_vocab(training_data)\n",
    "test_vocab, test_tokenized_corpus = create_vocab(test_data)\n",
    "\n",
    "# Creating joint vocab from test and train:\n",
    "joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([training_data, test_data]))\n",
    "\n",
    "print(\"Vocab created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tPA3lKyKkcq",
    "outputId": "9a2ec5db-78e5-4bb3-b68a-61929ab07cd5"
   },
   "outputs": [],
   "source": [
    "word2vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Xu5zHHbEB64",
    "outputId": "0b23c413-345d-4833-f7b0-4fa2c0cc54e3"
   },
   "outputs": [],
   "source": [
    "\"Germany\" in word2vec.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "r0drATEFHrSs",
    "outputId": "1e64bf4d-1861-4b90-f916-bfffe13d61c8"
   },
   "outputs": [],
   "source": [
    "word2vec.get_vector(\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJK-3bXkHGdQ"
   },
   "outputs": [],
   "source": [
    "word2vec.similar_by_vector(word2vec.get_vector(\"France\") - word2vec.get_vector(\"france\") + word2vec.get_vector(\"Germany\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DP-xBascDqzM",
    "outputId": "d69bd276-ccba-4b9d-b375-f26593198e3a"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "oov_words_counter = Counter(oov_words)\n",
    "print(oov_words_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bp9d32sOlDo6",
    "outputId": "978777c5-9b7b-4dc0-fc0d-a4c426f12e3e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f# We create representations for our tokens\n",
    "wvecs = [] # word vectors\n",
    "word2idx = [] # word2index\n",
    "idx2word = []\n",
    "\n",
    "out_of_\n",
    "\n",
    "index = 1\n",
    "for word in joint_vocab:\n",
    "  if word in word2vec.vocab:\n",
    "    vec = word2vec.get_vector(word)\n",
    "    wvecs.append(vec)\n",
    "    word2idx.append((word, index))\n",
    "    idx2word.append((index, word))\n",
    "    index += 1\n",
    "\n",
    "vector_dim = len(wvecs[0])\n",
    "wvecs.insert(0, np.zeros(vector_dim))\n",
    "wvecs = np.array(wvecs)\n",
    "word2idx = dict(word2idx)\n",
    "idx2word = dict(idx2word)\n",
    "\n",
    "vectorized_seqs = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in training_tokenized_corpus]\n",
    "\n",
    "# To avoid any sentences being empty (if no words match to our word embeddings)\n",
    "vectorized_seqs = [x if len(x) > 0 else [0] for x in vectorized_seqs]\n",
    "\n",
    "INPUT_DIM = len(word2idx)\n",
    "EMBEDDING_DIM = wvecs.shape[1]\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model = BiLSTM(EMBEDDING_DIM, 50, INPUT_DIM + 1, BATCH_SIZE, device)\n",
    "print(\"Model initialised.\")\n",
    "\n",
    "model.to(device)\n",
    "# We provide the model with our embeddings\n",
    "model.embedding.weight.data.copy_(torch.from_numpy(wvecs))\n",
    "\n",
    "feature = vectorized_seqs\n",
    "\n",
    "# 'feature' is a list of lists, each containing embedding IDs for word tokens\n",
    "train_and_dev = Task1Dataset(feature, train_df['meanGrade'])\n",
    "\n",
    "train_examples = round(len(train_and_dev)*train_proportion)\n",
    "dev_examples = len(train_and_dev) - train_examples\n",
    "\n",
    "train_dataset, dev_dataset = random_split(train_and_dev,\n",
    "                                           (train_examples,\n",
    "                                            dev_examples))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "\n",
    "print(\"Dataloaders created.\")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s171jZQEMhju",
    "outputId": "dd5c22a9-ebf3-4249-c8db-01b132bb66e0"
   },
   "outputs": [],
   "source": [
    "train(train_loader, dev_loader, model, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5GLR90E7haM"
   },
   "source": [
    "##### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxYjHr1r_NAI",
    "outputId": "aaf8d55b-381f-4100-9af4-c20b6c242b9d"
   },
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSHjBUWG93qQ"
   },
   "outputs": [],
   "source": [
    "vectorized_seqs_test = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in test_tokenized_corpus]\n",
    "\n",
    "# To avoid any sentences being empty (if no words match to our word embeddings)\n",
    "vectorized_seqs_test = [x if len(x) > 0 else [0] for x in vectorized_seqs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5lL8-cuByAW"
   },
   "outputs": [],
   "source": [
    "test_dataset = Task1Dataset(vectorized_seqs_test, test_df['meanGrade'])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MeDhp1va74r9",
    "outputId": "ba8278d1-67bd-4dc2-9cd2-43543f462958"
   },
   "outputs": [],
   "source": [
    "loss, mse, predictions, target = eval(test_loader, model)\n",
    "model_performance(predictions, target, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "zimIzi2Y78nT",
    "outputId": "dea38dc8-a266-4d03-ff51-414a068272fb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(predictions, bins=30)\n",
    "plt.hist(target, bins=30, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HV4E_ySK_ne"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3aXIWuRLEjx",
    "outputId": "3aaa7711-6a8f-4761-fba1-80332c5996e9"
   },
   "outputs": [],
   "source": [
    "explained_variance_score(target, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q54J8mU3LIbD",
    "outputId": "79e919f6-5e16-4af0-924e-b93287af1ba0"
   },
   "outputs": [],
   "source": [
    "r2_score(target, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2SYl0n6ET4v",
    "outputId": "3b01ff49-06e5-4681-82cf-c8a7f1d8ea6e"
   },
   "outputs": [],
   "source": [
    "print(min(predictions))\n",
    "print(max(predictions))\n",
    "rounded_preds = np.round_(predictions, decimals=1)\n",
    "print(min(rounded_preds))\n",
    "print(max(rounded_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "3pd0iteLL2_Q",
    "outputId": "01c6ce16-9abe-4888-ed08-335c4f4a69f7"
   },
   "outputs": [],
   "source": [
    "diff = abs(predictions - target)\n",
    "test_df['predictions'] = predictions\n",
    "test_df['difference'] = diff\n",
    "test_df['target'] = target\n",
    "results_df = test_df[diff > 0.5][['original', 'edit', 'meanGrade', 'predictions', 'target', 'difference']]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOVYDexwN2pT",
    "outputId": "c8876be5-2c88-4b3a-b48f-669e51fedbbd"
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "  index = results_df.index[i]\n",
    "  print(results_df['original'][index], \" | \", results_df['edit'][index], \" | \", results_df['meanGrade'][index], results_df['predictions'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHwGa_SiJPXe",
    "outputId": "e9e23a22-50ed-494c-8928-14140ec5950b"
   },
   "outputs": [],
   "source": [
    "np.var(target - predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "pIkzAqydLEU3",
    "outputId": "50e73284-7eb9-4c68-925b-3ce4ffde1fe0"
   },
   "outputs": [],
   "source": [
    "train_df['meanGrade'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "cMRvqg2qaebG",
    "outputId": "848fd93c-8149-456d-eeb0-d8635bf69592"
   },
   "outputs": [],
   "source": [
    "test_df[test_df['meanGrade'] >= 2.2]['meanGrade'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "gHibf5ElEzUy",
    "outputId": "5f2b1c21-9d9e-4548-a588-2776761ca2ca"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.relplot(x='meanGrade', y='predictions', data=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "nxnNeOTsHOme",
    "outputId": "593c9078-1cdb-4299-a7de-22c0a1614dab"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "conf = confusion_matrix(target * 10, rounded_preds * 10)\n",
    "plt.matshow(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Xm1Kx64I7m7",
    "outputId": "f281365c-4791-49cf-a8e5-533e4b5121ad"
   },
   "outputs": [],
   "source": [
    "print(classification_report(target * 10, rounded_preds * 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTNqPhIAcyw7"
   },
   "outputs": [],
   "source": [
    "train_and_dev_loader = torch.utils.data.DataLoader(train_and_dev, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Y2CJqXNcAe3",
    "outputId": "dff455b5-7cdb-4770-d1bd-3ab9de75e74a"
   },
   "outputs": [],
   "source": [
    "loss_t, mse_t, predictions_t, target_t = eval(train_and_dev_loader, model)\n",
    "model_performance(predictions_t, target_t, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3U_C4XfcWW7"
   },
   "outputs": [],
   "source": [
    "diff_t = abs(predictions_t - target_t)\n",
    "train_eval_df = train_df.copy(deep=True)\n",
    "train_eval_df['predictions'] = predictions_t\n",
    "train_eval_df['difference'] = diff_t\n",
    "train_eval_df['target'] = target_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "T1FtVWEddrp2",
    "outputId": "508101a7-854e-492e-c038-384c5328cf81"
   },
   "outputs": [],
   "source": [
    "sns.relplot(x='meanGrade', y='predictions', data=train_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "VkijFEZleJhC",
    "outputId": "22683f2c-62ec-4dc8-af31-4676f4435e54"
   },
   "outputs": [],
   "source": [
    "train_eval_df[['meanGrade', 'predictions']].boxplot(by='meanGrade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HFe38eJEgfrY",
    "outputId": "35e4c748-0faf-4fad-8515-449e039fe1a3"
   },
   "outputs": [],
   "source": [
    "\"\" in word2vec.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lASZyYXKewMP",
    "outputId": "eb61f72e-b51a-48f7-ae1a-8536e3c6dbcf"
   },
   "outputs": [],
   "source": [
    "low_grade = train_eval_df[(train_eval_df['meanGrade'] < 0.3) & (train_eval_df['difference'] >= 1.0)]\n",
    "low_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdeFaoc3lDpK"
   },
   "source": [
    "#### Approach 2: No pre-trained representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46gm47T4lDpQ"
   },
   "outputs": [],
   "source": [
    "train_and_dev = train_df['edit']\n",
    "\n",
    "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
    "                                                                        test_size=(1-train_proportion),\n",
    "                                                                        random_state=42)\n",
    "\n",
    "# We train a Tf-idf model\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "train_counts = count_vect.fit_transform(training_data)\n",
    "transformer = TfidfTransformer().fit(train_counts)\n",
    "train_counts = transformer.transform(train_counts)\n",
    "regression_model = LinearRegression().fit(train_counts, training_y)\n",
    "\n",
    "# Train predictions\n",
    "predicted_train = regression_model.predict(train_counts)\n",
    "\n",
    "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
    "test_and_test_counts = count_vect.transform(train_and_dev)\n",
    "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
    "\n",
    "test_counts = count_vect.transform(dev_data)\n",
    "\n",
    "test_counts = transformer.transform(test_counts)\n",
    "\n",
    "# Dev predictions\n",
    "predicted = regression_model.predict(test_counts)\n",
    "\n",
    "# We run the evaluation:\n",
    "print(\"\\nTrain performance:\")\n",
    "sse, mse = model_performance(predicted_train, training_y, True)\n",
    "\n",
    "print(\"\\nDev performance:\")\n",
    "sse, mse = model_performance(predicted, dev_y, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HyHwHkUlDpa"
   },
   "source": [
    "#### Baseline for task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DA3q4o1lDpd",
    "outputId": "1c4c8abb-29f2-474a-c088-96dfbceb5e9d"
   },
   "outputs": [],
   "source": [
    "# Baseline for the task\n",
    "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
    "print(\"\\nBaseline performance:\")\n",
    "sse, mse = model_performance(pred_baseline, dev_y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84nQDZyBlDpg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_CW_1 Using Gensim vectors",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
